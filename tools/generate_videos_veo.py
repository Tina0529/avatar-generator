#!/usr/bin/env python3
"""
ä½¿ç”¨ Google Veo API ç”Ÿæˆç‹å°ç‹¸æ•°å­—äººè§†é¢‘
ä½¿ç”¨ image_to_video æ–¹æ³•ï¼Œåœ¨ prompt ä¸­å¼ºè°ƒå›åˆ°èµ·å§‹å§¿åŠ¿
"""

import os
import sys
import time
import argparse
import mimetypes

try:
    from google import genai
    from google.genai import types
except ImportError:
    print("Error: google-genai not installed. Run: pip install google-genai")
    sys.exit(1)

try:
    from PIL import Image
except ImportError:
    print("Error: Pillow not installed. Run: pip install Pillow")
    sys.exit(1)

# é…ç½®
VIDEO_MODEL = "veo-3.1-generate-preview"
TARGET_ASPECT_RATIO = 9 / 16
MIN_WIDTH = 360
MIN_HEIGHT = 640

PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))
ASSETS_DIR = os.path.join(PROJECT_DIR, "assets")
IDLE_IMAGE = os.path.join(ASSETS_DIR, "idle.jpg")

# è§’è‰²æè¿°ï¼ˆç»Ÿä¸€ç”¨äºæ‰€æœ‰ promptï¼‰
CHARACTER = (
    "A cute cartoon 3D orange fox cub with big round brown eyes, white fluffy chest fur, "
    "and a bushy orange tail with a white tip, sitting on green grass in a sunlit forest"
)

# è§†é¢‘é…ç½®ï¼šåŠ¨ä½œåç§° -> (æç¤ºè¯, æ—¶é•¿)
VIDEOS = {
    "idle": (
        f"{CHARACTER}. The little fox sits perfectly still in a calm, relaxed resting pose. "
        "Extremely subtle, lifelike micro-movements only: very slow gentle breathing motion in the chest, "
        "occasional soft blink, and the tiniest ear twitch. "
        "No head movement, no paw movement, no body shifting. "
        "The overall impression is a peaceful, living creature at rest. Very minimal and natural. "
        "The pose at the end is exactly the same as the beginning, creating a seamless loop.",
        6
    ),
    "speaking": (
        f"{CHARACTER}. The little fox has subtle mouth movements and gentle facial expression changes. "
        "Its mouth opens and closes slightly as if talking, showing a friendly expression. "
        "Subtle ear twitching. "
        "At the end, it returns to the exact same neutral pose as the beginning with a calm, gentle smile.",
        6
    ),
    "listening": (
        f"{CHARACTER}. The little fox turns its head to the side and raises one front paw to its ear, "
        "then holds completely still in this listening pose. "
        "No mouth movement, no blinking, no body movement - perfectly still and focused. "
        "The expression is calm, quiet, and deeply concentrated, like carefully listening to a faint sound. "
        "The pose is maintained motionless throughout, simulating a real attentive listener. "
        "At the end, it slowly lowers its paw and turns back, returning to the exact same neutral pose as the beginning, "
        "with its head centered and a calm expression.",
        6
    ),
    "wave": (
        f"{CHARACTER}. The little fox raises one front paw and waves hello with a playful, cheerful expression. "
        "Its tail sways gently with excitement. The movement is cute and energetic. "
        "At the end, it lowers its paw and returns to the exact same neutral pose as the beginning, "
        "sitting calmly with paws on the ground.",
        6
    ),
    "nod": (
        f"{CHARACTER}. The little fox simply nods its head up and down slowly and clearly, showing agreement. "
        "Only the head moves - no paw movement, no body movement, no other gestures. "
        "The mouth stays closed, the body stays perfectly still, only the head nods gently. "
        "A soft, approving smile on its face. Minimal and clean motion. "
        "At the end, it stops nodding and returns to the exact same neutral pose as the beginning, "
        "with its head level and a calm expression.",
        6
    ),
    "think": (
        f"{CHARACTER}. The little fox shows a thoughtful expression, tilting its head slightly "
        "and looking upward with one paw raised near its chin. Its eyes look contemplative and curious. "
        "At the end, it lowers its paw and returns to the exact same neutral pose as the beginning, "
        "with a calm, neutral expression.",
        6
    ),
    "sneeze": (
        f"{CHARACTER}. The little fox's nose twitches rapidly, its eyes squint, "
        "then it lets out an adorable big sneeze - head jerking forward with ears flattening back. "
        "After the sneeze, it shakes its head and looks slightly dazed with a funny expression. "
        "At the end, it returns to the exact same neutral pose as the beginning, "
        "with a calm, gentle smile.",
        6
    ),
    "shy": (
        f"{CHARACTER}. The little fox suddenly becomes shy and bashful. "
        "It covers its face with both front paws, ears flatten back, and its tail curls around its body. "
        "It peeks through its paws with one eye, looking adorably embarrassed. "
        "At the end, it lowers its paws and returns to the exact same neutral pose as the beginning, "
        "sitting calmly with a gentle smile.",
        6
    ),
    "tail_wag": (
        f"{CHARACTER}. The little fox looks back at its own bushy tail, then starts wagging it "
        "enthusiastically from side to side with pure joy. Its whole body wiggles slightly with the movement. "
        "It looks happy and excited, ears perked up. "
        "At the end, it stops wagging and returns to the exact same neutral pose as the beginning, "
        "sitting calmly facing forward.",
        6
    ),
}


def check_and_crop_image(image_path: str, backup: bool = True) -> tuple:
    """æ£€æŸ¥å›¾ç‰‡å®½é«˜æ¯”ï¼Œå¦‚æœä¸æ˜¯ 9:16 åˆ™è‡ªåŠ¨è£å‰ª"""
    img = Image.open(image_path)
    w, h = img.size
    current_ratio = w / h

    print(f"å›¾ç‰‡å°ºå¯¸: {w}x{h}, å®½é«˜æ¯”: {current_ratio:.4f}")
    print(f"ç›®æ ‡å®½é«˜æ¯”: {TARGET_ASPECT_RATIO:.4f} (9:16)")

    if abs(current_ratio - TARGET_ASPECT_RATIO) < 0.01:
        print("âœ“ å›¾ç‰‡å®½é«˜æ¯”å·²ç»æ˜¯ 9:16ï¼Œæ— éœ€è£å‰ª")
        if w < MIN_WIDTH or h < MIN_HEIGHT:
            return False, f"å›¾ç‰‡å°ºå¯¸å¤ªå°ï¼ˆ{w}x{h}ï¼‰ï¼Œæœ€å°è¦æ±‚ {MIN_WIDTH}x{MIN_HEIGHT}"
        return True, "å›¾ç‰‡å·²ç¬¦åˆè¦æ±‚"

    print(f"å›¾ç‰‡å®½é«˜æ¯”ä¸æ˜¯ 9:16ï¼Œéœ€è¦è£å‰ª...")

    if current_ratio > TARGET_ASPECT_RATIO:
        new_w = int(h * TARGET_ASPECT_RATIO)
        new_h = h
        left = (w - new_w) // 2
        crop_box = (left, 0, left + new_w, h)
        print(f"è£å‰ªæ–¹å¼: å·¦å³è£å‰ªï¼Œä¿ç•™ä¸­é—´ {new_w} åƒç´ å®½åº¦")
    else:
        new_w = w
        new_h = int(w / TARGET_ASPECT_RATIO)
        left = 0
        top = (h - new_h) // 2
        crop_box = (left, top, w, top + new_h)
        print(f"è£å‰ªæ–¹å¼: ä¸Šä¸‹è£å‰ªï¼Œä¿ç•™ä¸­é—´ {new_h} åƒç´ é«˜åº¦")

    if new_w < MIN_WIDTH or new_h < MIN_HEIGHT:
        return False, (
            f"è£å‰ªåå°ºå¯¸å¤ªå°ï¼ˆ{new_w}x{new_h}ï¼‰ï¼Œæœ€å°è¦æ±‚ {MIN_WIDTH}x{MIN_HEIGHT}ã€‚\n"
            f"è¯·ä¸Šä¼ æ›´å¤§çš„å›¾ç‰‡ï¼Œå»ºè®®è‡³å°‘ {MIN_WIDTH}x{MIN_HEIGHT} åƒç´ ï¼Œå®½é«˜æ¯”æ¥è¿‘ 9:16ã€‚"
        )

    cropped = img.crop(crop_box)

    if backup:
        backup_path = image_path.rsplit('.', 1)
        backup_path = f"{backup_path[0]}_original.{backup_path[1]}"
        if not os.path.exists(backup_path):
            img.save(backup_path)
            print(f"åŸå›¾å·²å¤‡ä»½åˆ°: {backup_path}")

    if image_path.lower().endswith(('.jpg', '.jpeg')):
        cropped.save(image_path, quality=95)
    else:
        cropped.save(image_path)

    print(f"âœ“ è£å‰ªå®Œæˆ: {new_w}x{new_h}, å®½é«˜æ¯”: {new_w/new_h:.4f}")
    return True, f"å›¾ç‰‡å·²è£å‰ªä¸º {new_w}x{new_h}"


def load_image_as_bytes(image_path: str) -> tuple:
    """åŠ è½½å›¾ç‰‡å¹¶è¿”å›å­—èŠ‚æ•°æ®å’ŒMIMEç±»å‹"""
    with open(image_path, 'rb') as f:
        image_data = f.read()
    mime_type = mimetypes.guess_type(image_path)[0] or 'image/jpeg'
    return image_data, mime_type


def wait_for_video(video_client, operation) -> any:
    """ç­‰å¾…è§†é¢‘ç”Ÿæˆå®Œæˆ"""
    print("    ç­‰å¾…è§†é¢‘ç”Ÿæˆ...")
    check_count = 0
    while not operation.done:
        check_count += 1
        print(f"    ç”Ÿæˆä¸­... (ç¬¬ {check_count} æ¬¡æ£€æŸ¥)")
        time.sleep(10)
        operation = video_client.operations.get(operation)

    response = operation.response
    if not response:
        print(f"    å“åº”ä¸ºç©ºï¼Œoperation: {operation}")
        return None
    if not response.generated_videos:
        print(f"    æ²¡æœ‰ç”Ÿæˆè§†é¢‘ï¼Œresponse: {response}")
        return None
    return response.generated_videos[0]


def generate_video(video_client, action: str, prompt: str, duration: int) -> str:
    """ä½¿ç”¨ Veo API çš„ image_to_video æ–¹æ³•ç”Ÿæˆè§†é¢‘"""
    print(f"\n[{action}] å¼€å§‹ç”Ÿæˆè§†é¢‘...")
    print(f"  æ—¶é•¿: {duration}ç§’")
    print(f"  èµ·å§‹å¸§: {IDLE_IMAGE}")

    try:
        image_data, mime_type = load_image_as_bytes(IDLE_IMAGE)
        start_image = types.Image(image_bytes=image_data, mime_type=mime_type)

        config = types.GenerateVideosConfig(
            aspect_ratio="9:16",
            duration_seconds=duration,
            number_of_videos=1,
        )

        print("  å‘é€è¯·æ±‚...")
        operation = video_client.models.generate_videos(
            model=VIDEO_MODEL,
            prompt=prompt,
            image=start_image,
            config=config,
        )

        video = wait_for_video(video_client, operation)
        if not video:
            print("  é”™è¯¯: è§†é¢‘ç”Ÿæˆå¤±è´¥")
            return None

        output_path = os.path.join(ASSETS_DIR, f"{action}.mp4")
        video_client.files.download(file=video.video)
        video.video.save(output_path)
        print(f"  æˆåŠŸ! ä¿å­˜åˆ°: {output_path}")
        return output_path

    except Exception as e:
        print(f"  é”™è¯¯: {e}")
        return None


def main():
    parser = argparse.ArgumentParser(description='ä½¿ç”¨ Google Veo API ç”Ÿæˆç‹å°ç‹¸æ•°å­—äººè§†é¢‘')
    parser.add_argument('--api-key', '-k', required=True, help='Google AI API Key')
    parser.add_argument('--action', '-a', help='åªç”ŸæˆæŒ‡å®šåŠ¨ä½œçš„è§†é¢‘')
    parser.add_argument('--list', '-l', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨åŠ¨ä½œ')
    parser.add_argument('--no-crop', action='store_true', help='è·³è¿‡å›¾ç‰‡è£å‰ªæ£€æŸ¥')

    args = parser.parse_args()

    if args.list:
        print("å¯ç”¨åŠ¨ä½œ:")
        for action, (prompt, duration) in VIDEOS.items():
            print(f"  - {action} ({duration}ç§’)")
        return

    if not os.path.exists(IDLE_IMAGE):
        print(f"é”™è¯¯: é™æ€å›¾ä¸å­˜åœ¨: {IDLE_IMAGE}")
        return

    if not args.no_crop:
        print("=" * 50)
        print("æ£€æŸ¥å›¾ç‰‡å°ºå¯¸...")
        print("=" * 50)
        success, message = check_and_crop_image(IDLE_IMAGE)
        if not success:
            print(f"\nâŒ é”™è¯¯: {message}")
            return
        print()

    video_client = genai.Client(
        http_options={"api_version": "v1beta"},
        api_key=args.api_key,
    )

    if args.action:
        if args.action not in VIDEOS:
            print(f"é”™è¯¯: æœªçŸ¥åŠ¨ä½œ '{args.action}'")
            print(f"å¯ç”¨åŠ¨ä½œ: {', '.join(VIDEOS.keys())}")
            return
        videos_to_generate = {args.action: VIDEOS[args.action]}
    else:
        videos_to_generate = VIDEOS

    print("=" * 50)
    print("ğŸ¦Š ç‹å°ç‹¸ - Veo è§†é¢‘ç”Ÿæˆå™¨")
    print("=" * 50)
    print(f"æ¨¡å‹: {VIDEO_MODEL}")
    print(f"é™æ€å›¾: {IDLE_IMAGE}")
    print(f"è¾“å‡ºç›®å½•: {ASSETS_DIR}")
    print(f"å¾…ç”Ÿæˆè§†é¢‘: {len(videos_to_generate)} ä¸ª")
    print("=" * 50)

    success_count = 0
    fail_count = 0

    for action, (prompt, duration) in videos_to_generate.items():
        result = generate_video(video_client, action, prompt, duration)
        if result:
            success_count += 1
        else:
            fail_count += 1

    print("\n" + "=" * 50)
    print(f"ç”Ÿæˆå®Œæˆ! æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}")
    print("=" * 50)


if __name__ == "__main__":
    main()
